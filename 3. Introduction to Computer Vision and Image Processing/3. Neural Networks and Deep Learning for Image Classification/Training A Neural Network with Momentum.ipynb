{"cells":[{"cell_type":"markdown","metadata":{},"source":["<center>\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/IDSNlogo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n","</center>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h1>Training A Neural Network with Momentum</h1>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h3>Objective for this Notebook<h3>    \n","<h5> 1. Train Different Neural Networks Model different values for the Momentum Parameter.</h5>\n","<h5> 2. Compare Results of Different Momentum Terms. </h5>     \n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Table of Contents</h2>\n","<p>In this lab, you will see how different values for the momentum parameters affect the convergence rate of a neural network.</p>\n","\n","<ul>\n","<li><a href=\"https://#Model\">Neural Network Module and Function for Training</a></li>\n","<li><a href=\"https://#Train\">Train Different Neural Networks Model different values for the Momentum Parameter</a></li>\n","<li><a href=\"https://#Result\">Compare Results of Different Momentum Terms</a></li>\n","</ul>\n","<p>Estimated Time Needed: <strong>25 min</strong></p>\n","\n","<hr>\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Preparation</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["We'll need the following libraries:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import the libraries for this lab\n","\n","# Used to graph data and loss curves\n","import matplotlib.pyplot as plt \n","# Allows us to use arrays to manipulate and store data\n","import numpy as np\n","# PyTorch Library\n","import torch\n","# PyTorch Neural Network\n","import torch.nn as nn\n","# Allows us to use activation functions\n","import torch.nn.functional as F\n","# Used to graph data and loss curves\n","from matplotlib.colors import ListedColormap\n","# Used to help create the dataset and perform mini-batch\n","from torch.utils.data import Dataset, DataLoader\n","\n","torch.manual_seed(1)\n","np.random.seed(1)"]},{"cell_type":"markdown","metadata":{},"source":["Functions used to plot:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define a function to plot the decision region\n","\n","def plot_decision_regions_3class(model, data_set):\n","    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA','#00AAFF'])\n","    cmap_bold = ListedColormap(['#FF0000', '#00FF00','#00AAFF'])\n","    X=data_set.x.numpy()\n","    y=data_set.y.numpy()\n","    h = .02\n","    x_min, x_max = X[:, 0].min() - 0.1 , X[:, 0].max() + 0.1 \n","    y_min, y_max = X[:, 1].min() - 0.1 , X[:, 1].max() + 0.1 \n","    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n","    XX=torch.torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n","    _,yhat=torch.max(model(XX),1)\n","    yhat=yhat.numpy().reshape(xx.shape)\n","    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light, shading='auto')\n","    plt.plot(X[y[:]==0,0], X[y[:]==0,1], 'ro', label='y=0')\n","    plt.plot(X[y[:]==1,0], X[y[:]==1,1], 'go', label='y=1')\n","    plt.plot(X[y[:]==2,0], X[y[:]==2,1], 'o', label='y=2')\n","    plt.title(\"decision region\")\n","    plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":["Create the dataset class: We will display the dataset later below\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the dataset class\n","\n","class Data(Dataset):\n","    \n","    # modified from: http://cs231n.github.io/neural-networks-case-study/\n","    # Constructor\n","    def __init__(self, K=3, N=500):\n","        D = 2\n","        X = np.zeros((N * K, D)) # data matrix (each row = single example)\n","        y = np.zeros(N * K, dtype='uint8') # class labels\n","        for j in range(K):\n","          ix = range(N * j, N * (j + 1))\n","          r = np.linspace(0.0, 1, N) # radius\n","          t = np.linspace(j * 4, (j + 1) * 4, N) + np.random.randn(N) * 0.2 # theta\n","          X[ix] = np.c_[r * np.sin(t), r * np.cos(t)]\n","          y[ix] = j\n","    \n","        self.y = torch.from_numpy(y).type(torch.LongTensor)\n","        self.x = torch.from_numpy(X).type(torch.FloatTensor)\n","        self.len = y.shape[0]\n","            \n","    # Getter\n","    def __getitem__(self, index):    \n","        return self.x[index], self.y[index]\n","    \n","    # Get Length\n","    def __len__(self):\n","        return self.len\n","    \n","    # Plot the diagram\n","    def plot_data(self):\n","        plt.plot(self.x[self.y[:] == 0, 0].numpy(), self.x[self.y[:] == 0, 1].numpy(), 'o', label=\"y=0\")\n","        plt.plot(self.x[self.y[:] == 1, 0].numpy(), self.x[self.y[:] == 1, 1].numpy(), 'ro', label=\"y=1\")\n","        plt.plot(self.x[self.y[:] == 2, 0].numpy(),self.x[self.y[:] == 2, 1].numpy(), 'go',label=\"y=2\")\n","        plt.legend()"]},{"cell_type":"markdown","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"Model\">Neural Network Module and Function for Training</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["Create Neural Network Module using <code>ModuleList()</code>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create dataset object\n","\n","class Net(nn.Module):\n","    \n","    # Constructor\n","    # Given a list of integers, Layers, we create layers of the neural network where each integer in Layers corresponds to the layers number of neurons\n","    def __init__(self, Layers):\n","        super(Net, self).__init__()\n","        self.hidden = nn.ModuleList()\n","        for input_size, output_size in zip(Layers, Layers[1:]):\n","            self.hidden.append(nn.Linear(input_size, output_size))\n","    \n","    # Prediction\n","    # Puts the X value through each layer of the neural network while using the RELU activation function in between. The final output is not put through RELU.\n","    def forward(self, x):\n","        L = len(self.hidden)\n","        for (l, linear_transform) in zip(range(L), self.hidden):\n","            if l < L - 1:\n","                x = F.relu(linear_transform(x))    \n","            else:\n","                x = linear_transform(x)\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["Create the function for training the model.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define the function for training the model\n","\n","def train(data_set, model, criterion, train_loader, optimizer, epochs=100):\n","    # Lists to keep track of loss and accuracy\n","    LOSS = []\n","    ACC = []\n","    # Number of times we train on the entire dataset\n","    for epoch in range(epochs):\n","        # For batch in train laoder\n","        for x, y in train_loader:\n","            # Resets the calculated gradient value, this must be done each time as it accumulates if we do not reset\n","            optimizer.zero_grad()\n","            # Makes a prediction based on X value\n","            yhat = model(x)\n","            # Measures the loss between prediction and acutal Y value\n","            loss = criterion(yhat, y)\n","            # Calculates the gradient value with respect to each weight and bias\n","            loss.backward()\n","            # Updates the weight and bias according to calculated gradient value\n","            optimizer.step()\n","        # Saves loss and accuracy\n","        LOSS.append(loss.item())\n","        ACC.append(accuracy(model,data_set))\n","        \n","    # Prints the Loss and Accuracy vs Epoch graph\n","    results ={\"Loss\":LOSS, \"Accuracy\":ACC}\n","    fig, ax1 = plt.subplots()\n","    color = 'tab:red'\n","    ax1.plot(LOSS,color=color)\n","    ax1.set_xlabel('epoch', color=color)\n","    ax1.set_ylabel('total loss', color=color)\n","    ax1.tick_params(axis = 'y', color=color)\n","    \n","    ax2 = ax1.twinx()  \n","    color = 'tab:blue'\n","    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n","    ax2.plot(ACC, color=color)\n","    ax2.tick_params(axis='y', color=color)\n","    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","    \n","    plt.show()\n","    return results"]},{"cell_type":"markdown","metadata":{},"source":["Define a function used to calculate accuracy.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define a function for calculating accuracy\n","\n","def accuracy(model, data_set):\n","    _, yhat = torch.max(model(data_set.x), 1)\n","    return (yhat == data_set.y).numpy().mean()"]},{"cell_type":"markdown","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"Train\">Train Different Networks Model different values for the Momentum Parameter</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["Create a dataset object using <code>Data</code>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create the dataset and plot it\n","\n","data_set = Data()\n","data_set.plot_data()\n","data_set.y = data_set.y.view(-1)"]},{"cell_type":"markdown","metadata":{},"source":["Dictionary to contain different cost and  accuracy values for each epoch  for different values of the momentum parameter.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Initialize a dictionary to contain the cost and accuracy\n","\n","Results = {\"momentum 0\": {\"Loss\": 0, \"Accuracy:\": 0}, \"momentum 0.1\": {\"Loss\": 0, \"Accuracy:\": 0}}"]},{"cell_type":"markdown","metadata":{},"source":["Create a  network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of zero.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons\n","\n","# Size of input layer is 2, hidden layer is 50, and output layer is 3\n","# Our X values are x and y coordinates and this problem has 3 classes\n","Layers = [2, 50, 3]\n","# Create a model\n","model = Net(Layers)\n","learning_rate = 0.10\n","# Create an optimizer that updates model parameters using the learning rate, gradient, and no momentum\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","# Create a Data Loader for the training data with a batch size of 20\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","# We create a criterion which will measure loss\n","criterion = nn.CrossEntropyLoss()\n","# Use the training function to train the model for 100 epochs\n","Results[\"momentum 0\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","# Prints the dataset and decision boundaries\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.1.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.1 momentum\n","\n","# Size of input layer is 2, hidden layer is 50, and output layer is 3\n","# Our X values are x and y coordinates and this problem has 3 classes\n","Layers = [2, 50, 3]\n","# Create a model\n","model = Net(Layers)\n","learning_rate = 0.10\n","# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.1 momentum\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.1)\n","# Create a Data Loader for the training data with a batch size of 20\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","# We create a criterion which will measure loss\n","criterion = nn.CrossEntropyLoss()\n","# Use the training function to train the model for 100 epochs\n","Results[\"momentum 0.1\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","# Prints the dataset and decision boundaries\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.2.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.2 momentum\n","\n","# Size of input layer is 2, hidden layer is 50, and output layer is 3\n","# Our X values are x and y coordinates and this problem has 3 classes\n","Layers = [2, 50, 3]\n","# Create a model\n","model = Net(Layers)\n","learning_rate = 0.10\n","# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.2 momentum\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.2)\n","# Create a Data Loader for the training data with a batch size of 20\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","# We create a criterion which will measure loss\n","criterion = nn.CrossEntropyLoss()\n","# Use the training function to train the model for 100 epochs\n","Results[\"momentum 0.2\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","# Prints the dataset and decision boundaries\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.4.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.4 momentum\n","\n","# Size of input layer is 2, hidden layer is 50, and output layer is 3\n","# Our X values are x and y coordinates and this problem has 3 classes\n","Layers = [2, 50, 3]\n","# Create a model\n","model = Net(Layers)\n","learning_rate = 0.10\n","# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.4 momentum\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.4)\n","# Create a Data Loader for the training data with a batch size of 20\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","# We create a criterion which will measure loss\n","criterion = nn.CrossEntropyLoss()\n","# Use the training function to train the model for 100 epochs\n","Results[\"momentum 0.4\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","# Prints the dataset and decision boundaries\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["Create a network to classify three classes with 1 hidden layer with 50 neurons and a momentum value of 0.5.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train a model with 1 hidden layer and 50 neurons with 0.5 momentum\n","\n","# Size of input layer is 2, hidden layer is 50, and output layer is 3\n","# Our X values are x and y coordinates and this problem has 3 classes\n","Layers = [2, 50, 3]\n","# Create a model\n","model = Net(Layers)\n","learning_rate = 0.10\n","# Create an optimizer that updates model parameters using the learning rate, gradient, and 0.5 momentum\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.5)\n","# Create a Data Loader for the training data with a batch size of 20\n","train_loader = DataLoader(dataset=data_set, batch_size=20)\n","# We create a criterion which will measure loss\n","criterion = nn.CrossEntropyLoss()\n","# Use the training function to train the model for 100 epochs\n","Results[\"momentum 0.5\"] = train(data_set, model, criterion, train_loader, optimizer, epochs=100)\n","# Prints the dataset and decision boundaries\n","plot_decision_regions_3class(model, data_set)"]},{"cell_type":"markdown","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2 id=\"Result\">Compare Results of Different Momentum Terms</h2>\n"]},{"cell_type":"markdown","metadata":{},"source":["The plot below compares the results of different momentum terms. We see that in general. The Cost decreases proportionally to the momentum term, but larger momentum terms lead to larger oscillations. While the momentum term decreases faster, it seems that a momentum term of 0.2 reaches the smallest value for the cost.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Loss result for each term\n","\n","for key, value in Results.items():\n","    plt.plot(value['Loss'],label=key)\n","    plt.legend()\n","    plt.xlabel('epoch')\n","    plt.ylabel('Total Loss or Cost')"]},{"cell_type":"markdown","metadata":{},"source":["The  accuracy seems to be proportional to the momentum term.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot the Accuracy result for each term\n","\n","for key, value in Results.items():\n","    plt.plot(value['Accuracy'],label=key)\n","    plt.legend()\n","    plt.xlabel('epoch')\n","    plt.ylabel('Accuracy')"]},{"cell_type":"markdown","metadata":{},"source":["<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera25797139-2021-01-01&context=cpdaas&apps=data_science_experience%2Cwatson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"/></a>\n"]},{"cell_type":"markdown","metadata":{},"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera25797139-2021-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","metadata":{},"source":["Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera25797139-2021-01-01\">Michelle Carey</a>, <a href=\"https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkCV0101ENCoursera25797139-2021-01-01\">Mavis Zhou</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n","\n","| Date (YYYY-MM-DD) | Version | Changed By | Change Description                                          |\n","| ----------------- | ------- | ---------- | ----------------------------------------------------------- |\n","| 2020-09-23        | 2.0     | Srishti    | Migrated Lab to Markdown and added to course repo in GitLab |\n","\n","<hr>\n","\n","## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":4}