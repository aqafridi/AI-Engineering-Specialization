{"cells":[{"cell_type":"markdown","metadata":{},"source":["<img src=\"http://vision.skills.network/logo-light.png\" width=\"400\" alt=\"CV Studio logo\"  />\n"]},{"cell_type":"markdown","metadata":{},"source":["<h2>Transfer Learning with Convolutional Neural Networks For Classification with PyTorch and   <a href=\"https://vision.skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-cvstudio-2021-01-01\"> Computer Vision Learning \n","Studio\n"," (CV Studio)</a></h2> <p><b> V 0.2</b></p>\n","<h4>Project: Final_project_stop_signs</h4>\n","<h4>Training Run: Transfer learning for Stop Sign Classification</h4>\n"]},{"cell_type":"markdown","metadata":{},"source":["Estimated time needed: **40** minutes\n"]},{"cell_type":"markdown","metadata":{},"source":["In this lab, you will train a deep neural network for  image classification using <a href=\"https://cs231n.github.io/transfer-learning/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-cvstudio-2021-01-01\">transfer learning</a>, the image dataset will automatically be download from your <a href=\"https://vision.skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-cvstudio-2021-01-01\">CV Studio</a> account. Experiment with different hyperparameters.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Objectives\n"]},{"cell_type":"markdown","metadata":{},"source":["In this lab you will train a state of the art image classifier using and <a href=\"https://vision.skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-cvstudio-2021-01-01\">CV Studio</a>, CV Studio is a fast, easy and collaborative open source image annotation tool for teams and individuals. In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset in the lab, then use this Network to train your model. We will use the Convolutional Network as a feature generator, only training the output layer.  In general, 100-200 images will give you a good starting point, and it only takes about half an hour.  Usually, the more images you add, the better your results, but it takes longer and the rate of improvement will decrease.\n"]},{"cell_type":"markdown","metadata":{},"source":["-   Import Libraries and Define Auxiliary Functions\n","-   Create Dataset Object\n","-   Load Model and Train\n"]},{"cell_type":"markdown","metadata":{},"source":["* * *\n"]},{"cell_type":"markdown","metadata":{},"source":["## Import Libraries and Define Auxiliary Functions\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#! conda install -c pytorch torchvision\n","#! pip install skillsnetwork tqdm\n","#!pip install  skillsnetwork"]},{"cell_type":"markdown","metadata":{},"source":["Libraries for OS and Cloud\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import uuid\n","import shutil\n","import json\n","from botocore.client import Config\n","import ibm_boto3\n","import copy\n","from datetime import datetime\n","from skillsnetwork import cvstudio "]},{"cell_type":"markdown","metadata":{},"source":["Libraries for Data Processing and Visualization\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import math\n","from matplotlib.pyplot import imshow\n","from tqdm import tqdm\n","from ipywidgets import IntProgress\n","import time "]},{"cell_type":"markdown","metadata":{},"source":["Deep Learning Libraries\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader,random_split\n","from torch.optim import lr_scheduler\n","from torchvision import transforms\n","import torch.nn as nn\n","torch.manual_seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["Plot train cost and validation accuracy:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_stuff(COST,ACC):    \n","    fig, ax1 = plt.subplots()\n","    color = 'tab:red'\n","    ax1.plot(COST, color = color)\n","    ax1.set_xlabel('Iteration', color = color)\n","    ax1.set_ylabel('total loss', color = color)\n","    ax1.tick_params(axis = 'y', color = color)\n","    \n","    ax2 = ax1.twinx()  \n","    color = 'tab:blue'\n","    ax2.set_ylabel('accuracy', color = color)  # we already handled the x-label with ax1\n","    ax2.plot(ACC, color = color)\n","    ax2.tick_params(axis = 'y', color = color)\n","    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n","    \n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Plot the transformed image:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def imshow_(inp, title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = inp .permute(1, 2, 0).numpy() \n","    print(inp.shape)\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","\n","    plt.imshow(inp)\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  \n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["Compare the prediction and actual value:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def result(model,x,y):\n","    #x,y=sample\n","    z=model(x.unsqueeze_(0))\n","    _,yhat=torch.max(z.data, 1)\n","    \n","    if yhat.item()!=y:\n","        text=\"predicted: {} actual: {}\".format(str(yhat.item()),y)\n","        print(text)"]},{"cell_type":"markdown","metadata":{},"source":["Define our device as the first visible cuda device if we have CUDA available:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"the device type is\", device)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Load Data\n"]},{"cell_type":"markdown","metadata":{},"source":["In this section we will preprocess our dataset by changing the shape of the image, converting to tensor and normalizing the image channels. These are the default preprocessing steps for image data. In addition, we will perform data augmentation on the training dataset. The preprocessing steps for the test dataset is the same, but W do not prform data augmentation on the test dataset. \n"]},{"cell_type":"markdown","metadata":{},"source":["<code>\n","<p>mean = [0.485, 0.456, 0.406]</p>\n","<p>std = [0.229, 0.224, 0.225]</p>\n","<p>composed = transforms.Compose([transforms.Resize((224, 224)),\n","        transforms.RandomHorizontalFlip(),transforms.RandomRotation(degrees=5)\n","                               , transforms.ToTensor()\n","                               , transforms.Normalize(mean, std)])</p>\n","    </code>\n"]},{"cell_type":"markdown","metadata":{},"source":["Download the data:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Get the Dataset\n","# Initialize the CV Studio Client\n","cvstudioClient = cvstudio.CVStudio()\n","# # Download All Images\n","cvstudioClient.downloadAll()"]},{"cell_type":"markdown","metadata":{},"source":["We need to get our training and validation dataset. 90% of the data will be used for training.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["percentage_train=0.9\n","train_set=cvstudioClient.getDataset(train_test='train',percentage_train=percentage_train)\n","val_set=cvstudioClient.getDataset(train_test='test',percentage_train=percentage_train)"]},{"cell_type":"markdown","metadata":{},"source":["We can plot some of our dataset:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["i=0\n","\n","for x,y  in val_set:\n","    imshow_(x,\"y=: {}\".format(str(y.item())))\n","    i+=1\n","    if i==3:\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameters\n"]},{"cell_type":"markdown","metadata":{},"source":["Experiment with different hyperparameters:\n"]},{"cell_type":"markdown","metadata":{},"source":["<b>Epoch</b> indicates the number of passes of the entire training dataset, here we will set the number of epochs to 10:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_epochs=10"]},{"cell_type":"markdown","metadata":{},"source":["<b>Batch size</b> is the number of training samples utilized in one iteration. If the batch size is equal to the total number of samples in the training set, then every epoch has one iteration. In Stochastic Gradient Descent, the batch size is set to one. A batch size of 32--512 data points seems like a good value, for more information check out the following <a href=\"https://arxiv.org/abs/1609.04836?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-cvstudio-2021-01-01\">link</a>.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["batch_size=32"]},{"cell_type":"markdown","metadata":{},"source":[" <b>Learning rate</b> is used in the training of neural networks. Learning rate is a hyperparameter with a small positive value, often in the range between 0.0 and 1.0.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lr=0.000001"]},{"cell_type":"markdown","metadata":{},"source":["<b>Momentum</b> is a term used in the gradient descent algorithm to improve training results:\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["momentum=0.9"]},{"cell_type":"markdown","metadata":{},"source":["If you set to <code>lr_scheduler=True</code>  for every epoch use a learning rate scheduler changes the range of the learning rate from a maximum or minimum value. The learning rate usually decays over time.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lr_scheduler=True\n","base_lr=0.001\n","max_lr=0.01"]},{"cell_type":"markdown","metadata":{},"source":["# Load Model and Train\n"]},{"cell_type":"markdown","metadata":{},"source":["This function will train the model \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train_model(model, train_loader,validation_loader, criterion, optimizer, n_epochs,print_=True):\n","    loss_list = []\n","    accuracy_list = []\n","    correct = 0\n","    #global:val_set\n","    n_test = len(val_set)\n","    accuracy_best=0\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","\n","    # Loop through epochs\n","        # Loop through the data in loader\n","    print(\"The first epoch should take several minutes\")\n","    for epoch in tqdm(range(n_epochs)):\n","        \n","        loss_sublist = []\n","        # Loop through the data in loader\n","\n","        for x, y in train_loader:\n","            x, y=x.to(device), y.to(device)\n","            model.train() \n","\n","            z = model(x)\n","            loss = criterion(z, y)\n","            loss_sublist.append(loss.data.item())\n","            loss.backward()\n","            optimizer.step()\n","\n","            optimizer.zero_grad()\n","        print(\"epoch {} done\".format(epoch) )\n","\n","        scheduler.step()    \n","        loss_list.append(np.mean(loss_sublist))\n","        correct = 0\n","\n","\n","        for x_test, y_test in validation_loader:\n","            x_test, y_test=x_test.to(device), y_test.to(device)\n","            model.eval()\n","            z = model(x_test)\n","            _, yhat = torch.max(z.data, 1)\n","            correct += (yhat == y_test).sum().item()\n","        accuracy = correct / n_test\n","        accuracy_list.append(accuracy)\n","        if accuracy>accuracy_best:\n","            accuracy_best=accuracy\n","            best_model_wts = copy.deepcopy(model.state_dict())\n","        \n","        \n","        if print_:\n","            print('learning rate',optimizer.param_groups[0]['lr'])\n","            print(\"The validaion  Cost for each epoch \" + str(epoch + 1) + \": \" + str(np.mean(loss_sublist)))\n","            print(\"The validation accuracy for epoch \" + str(epoch + 1) + \": \" + str(accuracy)) \n","    model.load_state_dict(best_model_wts)    \n","    return accuracy_list,loss_list, model"]},{"cell_type":"markdown","metadata":{},"source":[" Load the pre-trained model resnet18. Set the parameter pretrained to true.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = models.resnet18(pretrained=True)"]},{"cell_type":"markdown","metadata":{},"source":["We will only train the last layer of the network set the parameter <code>requires_grad</code> to <code>False</code>, the network is a fixed feature extractor.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[" for param in model.parameters():\n","        param.requires_grad = False\n","    "]},{"cell_type":"markdown","metadata":{},"source":["Number of classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_classes=train_set.n_classes\n","n_classes"]},{"cell_type":"markdown","metadata":{},"source":["Replace the output layer model.fc of the neural network with a nn.Linear object, to classify <code>n_classes</code> different classes. For the parameters in_features  remember the last hidden layer has 512 neurons.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Type your code here\n","model.fc = nn.Linear(512, n_classes)"]},{"cell_type":"markdown","metadata":{},"source":["Set device type\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["Cross-entropy loss, or log loss, measures the performance of a classification model combines LogSoftmax in one object class. It is useful when training a classification problem with C classes.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()"]},{"cell_type":"markdown","metadata":{},"source":["Create a training loader and validation loader object.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","train_loader = torch.utils.data.DataLoader(dataset=train_set , batch_size=batch_size,shuffle=True)\n","validation_loader= torch.utils.data.DataLoader(dataset=val_set , batch_size=1)"]},{"cell_type":"markdown","metadata":{},"source":["Use the optim package to define an Optimizer that will update the weights of the model for us. \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n"]},{"cell_type":"markdown","metadata":{},"source":["We use <a href='https://arxiv.org/pdf/1506.01186.pdf?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-cvstudio-2021-01-01'>Cyclical Learning Rates</a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if lr_scheduler:\n","    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.001, max_lr=0.01,step_size_up=5,mode=\"triangular2\")"]},{"cell_type":"markdown","metadata":{},"source":["Now we are going to train model,for 500 images this take 25 minutes, depending on your dataset\n"]},{"cell_type":"markdown","metadata":{},"source":["<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-Coursera/images/this_make_take_time.gif\" alt=\"this may take some time\">\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["start_datetime = datetime.now()\n","start_time=time.time()\n","\n","accuracy_list,loss_list, model=train_model(model,train_loader , validation_loader, criterion, optimizer, n_epochs=n_epochs)\n","\n","end_datetime = datetime.now()\n","current_time = time.time()\n","elapsed_time = current_time - start_time\n","print(\"elapsed time\", elapsed_time )"]},{"cell_type":"markdown","metadata":{},"source":["Now run the following to report back the results of the training run to CV Studio\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","parameters = {\n","    'epochs': n_epochs,\n","    'learningRate': lr,\n","    'momentum':momentum,\n","    'percentage used training':percentage_train,\n","    \"learningRatescheduler\": {\"lr_scheduler\":lr_scheduler,\"base_lr\":base_lr, \"max_lr\" :max_lr}\n","    \n","    \n","}\n","result = cvstudioClient.report(started=start_datetime, completed=end_datetime, parameters=parameters, accuracy={ 'accuracy': accuracy_list, 'loss': loss_list })\n","\n","if result.ok:\n","    print('Congratulations your results have been reported back to CV Studio!')"]},{"cell_type":"markdown","metadata":{},"source":["Save the model to model.pt\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the model to model.pt\n","torch.save(model.state_dict(), 'model.pt')\n","\n","# Save the model and report back to CV Studio\n","result = cvstudioClient.uploadModel('model.pt', {'numClasses': n_classes})"]},{"cell_type":"markdown","metadata":{},"source":["Plot train cost and validation accuracy,  you can improve results by getting more data.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_stuff(loss_list,accuracy_list)"]},{"cell_type":"markdown","metadata":{},"source":["Load the model that performs best:  \n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = models.resnet18(pretrained=True)\n","model.fc = nn.Linear(512, n_classes)\n","model.load_state_dict(torch.load( \"model.pt\"))\n","model.eval()"]},{"cell_type":"markdown","metadata":{},"source":["## What's Next\n"]},{"cell_type":"markdown","metadata":{},"source":["You can also deploy your model via Web Application or Web App . This allows users to interact with your model like a website. They can upload the image with a user interface and view the results. Let's see how we can deploy a web app in CV Studio. In CV Studio, go to the use model section and select New Application. Fill out the window as follows,  giving  your model a name and selecting the Model in this project, select **TEST - 1-click Deploy your Model to Cloud (Code Engine)** and  select the model from the  training run as shown here: \n","\n","<p>\n","<img  src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images/Image_2021-05-20_at_8.04_AM.jpeg\"  alt=\"popup\" width=\"400\" height=\"500\">\n","</p>\n","\n","Then once the window is filled out press the Create Application button and your model will begin deploying.\n","\n","<p>\n","<img  src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images/Image_2021-05-20_at_8.07_AM.jpeg\"  alt=\"popup\" width=\"500\" height=\"100\">\n","</p>\n","\n","Wait until the status changes from \"deploying\" to \"ready\". Once the status changes to ready, your application is ready for you to use!\n","\n","<p>\n","<img  src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images/Image_2021-05-20_at_8.08_AM.jpeg\"  alt=\"popup\" width=\"500\" height=\"100\">\n","</p>\n","\n","You can press the URL to go to your web application.\n","\n","<p>\n","<img  src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images/Image_2021-05-20_at_3.12_PM.jpeg\"  alt=\"popup\" width=\"500\" height=\"400\">\n","</p>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Authors\n"]},{"cell_type":"markdown","metadata":{},"source":["Joseph Santarcangelo,has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change Log\n"]},{"cell_type":"markdown","metadata":{},"source":["| Date (YYYY-MM-DD) | Version | Changed By | Change Description      |\n","| ----------------- | ------- | ---------- | ----------------------- |\n","| 2021-05-25        | 0.3     | Yasmine    | Modifies Multiple Areas |\n","| 2021-05-25        | 0.3     | Kathy      | Modified Multple Areas. |\n","| 2021-03-08        | 0.2     | Joseph     | Modified Multiple Areas |\n","| 2021-02-01        | 0.1     | Joseph     | Modified Multiple Areas |\n"]},{"cell_type":"markdown","metadata":{},"source":["Copyright Â© 2021 IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.13"}},"nbformat":4,"nbformat_minor":4}